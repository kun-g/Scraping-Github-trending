# å®šæ—¶æŠ“å–Github Trendingé‡Œçš„æ•°æ®

ä½œä¸ºä¸€ä¸ªé—´æ­‡æ€§â€œæ¾é¼ ç—‡â€æ‚£è€…ï¼Œæœ‰æ—¶å€™ä¼šèŠ±å‡ ä¸ªå°æ—¶é€›Github Trendingï¼Œç”Ÿæ€•æ¼æ‰ä»€ä¹ˆé‡è¦çš„ä¸œè¥¿ï¼Œè¯´åˆ°åº•æ˜¯å¿ƒç†ä½œç”¨ç½¢äº†ã€‚

è€Œè¿™ä¸ªGithub Trendçˆ¬è™«ï¼Œå°±æ˜¯æˆ‘ç»™è‡ªå·±å¼€çš„ä¸€å‘³è¯ï¼Œéƒ½æ”¶é›†èµ·æ¥ï¼Œå°±ä¸æ€•æ¼æ‰å•¥äº†ï¼ˆè™½ç„¶è¿™ä¸ªé€»è¾‘ç»ä¸èµ·æ¨æ•²ï¼Œä¸è¿‡ç¡®å®éƒ¨ç½²è¿™ä¸ªçˆ¬è™«ä¹‹åï¼Œæˆ‘å†ä¹Ÿæ²¡æœ‰é€›è¿‡Github Trendï¼‰

* åŸºäº[Github Actions](https://docs.github.com/en/actions)çš„çˆ¬è™«
* ä½¿ç”¨[click](https://github.com/pallets/click)å®ç°äº†å‘½ä»¤è¡Œå‚æ•°
* ä½¿ç”¨[Crontab Guru](https://crontab.guru/)æ¥è®¾ç½®å®šæ—¶å‚æ•°

# Repos
## ä»Šæ—¥TOP10 
<!-- START OF DAILY_TOP10_REPOS -->
| åå­— | ç®€ä»‹ |
| :----: | :----: |
| [llama2.c](https://github.com/karpathy/llama2.c) | Inference Llama 2 in one file of pure C |
| [llama2-webui](https://github.com/liltom-eth/llama2-webui) | Run Llama 2 locally with gradio UI on GPU or CPU from anywhere (Linux/Windows/Mac). Supporting Llama-2-7B/13B/70B with 8-bit, 4-bit. Supporting GPU inference (6 GB VRAM) and CPU inference. |
| [localGPT](https://github.com/PromtEngineer/localGPT) | Chat with your documents on your local device using GPT models. No data leaves your device and 100% private. |
| [ML-For-Beginners](https://github.com/microsoft/ML-For-Beginners) | 12 weeks, 26 lessons, 52 quizzes, classic Machine Learning for all |
| [TypeChat](https://github.com/microsoft/TypeChat) | TypeChat is a library that makes it easy to build natural language interfaces using types. |
| [TokenFlow](https://github.com/omerbt/TokenFlow) | Official Pytorch Implementation for "TokenFlow: Consistent Diffusion Features for Consistent Video Editing" presenting "TokenFlow" |
| [Chess-Challenge](https://github.com/SebLague/Chess-Challenge) | https://youtu.be/iScy18pVR58 |
| [chinese-independent-developer](https://github.com/1c7/chinese-independent-developer) | ğŸ‘©ğŸ¿â€ğŸ’»ğŸ‘¨ğŸ¾â€ğŸ’»ğŸ‘©ğŸ¼â€ğŸ’»ğŸ‘¨ğŸ½â€ğŸ’»ğŸ‘©ğŸ»â€ğŸ’»ä¸­å›½ç‹¬ç«‹å¼€å‘è€…é¡¹ç›®åˆ—è¡¨ -- åˆ†äº«å¤§å®¶éƒ½åœ¨åšä»€ä¹ˆ |
| [InvokeAI](https://github.com/invoke-ai/InvokeAI) | InvokeAI is a leading creative engine for Stable Diffusion models, empowering professionals, artists, and enthusiasts to generate and create visual media using the latest AI-driven technologies. The solution offers an industry leading WebUI, supports terminal use through a CLI, and serves as the foundation for multiple commercial products. |
| [text-generation-webui-colab](https://github.com/camenduru/text-generation-webui-colab) | A colab gradio web UI for running Large Language Models |
<!-- END OF DAILY_TOP10_REPOS -->

## æœ¬å‘¨TOP10
<!-- START OF WEEKLY_TOP10_REPOS -->
| åå­— | ç®€ä»‹ |
| :----: | :----: |
| [llama](https://github.com/facebookresearch/llama) | Inference code for LLaMA models |
| [free-programming-books](https://github.com/EbookFoundation/free-programming-books) | ğŸ“š Freely available programming books |
| [flash-attention](https://github.com/Dao-AILab/flash-attention) | Fast and memory-efficient exact attention |
| [LazyVim](https://github.com/LazyVim/LazyVim) | Neovim config for the lazy |
| [simpleaichat](https://github.com/minimaxir/simpleaichat) | Python package for easily interfacing with chat apps, with robust features and minimal code complexity. |
| [faster-whisper](https://github.com/guillaumekln/faster-whisper) | Faster Whisper transcription with CTranslate2 |
| [danswer](https://github.com/danswer-ai/danswer) | Ask Questions in natural language and get Answers backed by private sources. Connects to tools like Slack, GitHub, Confluence, etc. |
| [MetaGPT](https://github.com/geekan/MetaGPT) | ğŸŒŸ The Multi-Agent Meta Programming Framework: Given one line Requirement, return PRD, Design, Tasks, Repo |
| [alist](https://github.com/alist-org/alist) | ğŸ—‚ï¸A file list program that supports multiple storages, powered by Gin and Solidjs. / ä¸€ä¸ªæ”¯æŒå¤šå­˜å‚¨çš„æ–‡ä»¶åˆ—è¡¨ç¨‹åºï¼Œä½¿ç”¨ Gin å’Œ Solidjsã€‚ |
| [h2ogpt](https://github.com/h2oai/h2ogpt) | Private Q&A and summarization of documents+images or chat with local GPT, 100% private, Apache 2.0. Supports LLaMa2, llama.cpp, and more. Demo: https://gpt.h2o.ai/ |
<!-- END OF WEEKLY_TOP10_REPOS -->

## æœ¬æœˆTOP10
<!-- START OF MONTHLY_TOP10_REPOS -->
| åå­— | ç®€ä»‹ |
| :----: | :----: |
| [llama](https://github.com/facebookresearch/llama) | Inference code for LLaMA models |
| [quivr](https://github.com/StanGirard/quivr) | ğŸ§  Dump all your files and chat with it using your Generative AI Second Brain using LLMs ( GPT 3.5/4, Private, Anthropic, VertexAI ) & Embeddings ğŸ§  |
| [chatgpt-retrieval](https://github.com/techleadhd/chatgpt-retrieval) |  |
| [vllm](https://github.com/vllm-project/vllm) | A high-throughput and memory-efficient inference and serving engine for LLMs |
| [platforms](https://github.com/vercel/platforms) | A full-stack Next.js app with multi-tenancy and custom domain support. Built with Next.js App Router and the Vercel Domains API. |
| [tinygrad](https://github.com/tinygrad/tinygrad) | You like pytorch? You like micrograd? You love tinygrad! â¤ï¸ |
| [h2ogpt](https://github.com/h2oai/h2ogpt) | Private Q&A and summarization of documents+images or chat with local GPT, 100% private, Apache 2.0. Supports LLaMa2, llama.cpp, and more. Demo: https://gpt.h2o.ai/ |
| [ChatGLM-Efficient-Tuning](https://github.com/hiyouga/ChatGLM-Efficient-Tuning) | Fine-tuning ChatGLM-6B with PEFT | åŸºäº PEFT çš„é«˜æ•ˆ ChatGLM å¾®è°ƒ |
| [annotated_deep_learning_paper_implementations](https://github.com/labmlai/annotated_deep_learning_paper_implementations) | ğŸ§‘â€ğŸ« 60 Implementations/tutorials of deep learning papers with side-by-side notes ğŸ“; including transformers (original, xl, switch, feedback, vit, ...), optimizers (adam, adabelief, sophia, ...), gans(cyclegan, stylegan2, ...), ğŸ® reinforcement learning (ppo, dqn), capsnet, distillation, ... ğŸ§  |
| [AFFiNE](https://github.com/toeverything/AFFiNE) | There can be more than Notion and Miro. AFFiNE is a next-gen knowledge base that brings planning, sorting and creating all together. Privacy first, open-source, customizable and ready to use. |
<!-- END OF MONTHLY_TOP10_REPOS -->
